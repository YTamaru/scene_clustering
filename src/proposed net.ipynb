{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pprint\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "from roi_data_layer.roidb import combined_roidb\n",
    "from roi_data_layer.roibatchLoader import roibatchLoader\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n",
    "from model.utils.net_utils import weights_normal_init, save_net, load_net, \\\n",
    "      adjust_learning_rate, save_checkpoint, clip_gradient\n",
    "\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "from model.faster_rcnn.resnet import resnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sampler(Sampler):\n",
    "  def __init__(self, train_size, batch_size):\n",
    "    self.num_data = train_size\n",
    "    self.num_per_batch = int(train_size / batch_size)\n",
    "    self.batch_size = batch_size\n",
    "    self.range = torch.arange(0,batch_size).view(1, batch_size).long()\n",
    "    self.leftover_flag = False\n",
    "    if train_size % batch_size:\n",
    "      self.leftover = torch.arange(self.num_per_batch*batch_size, train_size).long()\n",
    "      self.leftover_flag = True\n",
    "\n",
    "  def __iter__(self):\n",
    "    rand_num = torch.randperm(self.num_per_batch).view(-1,1) * self.batch_size\n",
    "    self.rand_num = rand_num.expand(self.num_per_batch, self.batch_size) + self.range\n",
    "\n",
    "    self.rand_num_view = self.rand_num.view(-1)\n",
    "\n",
    "    if self.leftover_flag:\n",
    "      self.rand_num_view = torch.cat((self.rand_num_view, self.leftover),0)\n",
    "\n",
    "    return iter(self.rand_num_view)\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.num_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  args = parse_args()\n",
    "\n",
    "  print('Called with args:')\n",
    "  print(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "# -- Note: Use validation set and disable the flipped to enable faster loading.\n",
    "TRAIN.USE_FLIPPED = True\n",
    "USE_GPU_NMS = args.cuda\n",
    "imdb, roidb, ratio_list, ratio_index = combined_roidb('imagenet')\n",
    "train_size = len(roidb)\n",
    "\n",
    "print('{:d} roidb entries'.format(len(roidb)))\n",
    "\n",
    "output_dir = args.save_dir + \"/\" + args.net + \"/\" + args.dataset\n",
    "if not os.path.exists(output_dir):\n",
    "os.makedirs(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_batch = sampler(train_size, args.batch_size)\n",
    "\n",
    "dataset = roibatchLoader(roidb, ratio_list, ratio_index, args.batch_size, \\\n",
    "                       imdb.num_classes, training=True)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size,\n",
    "                        sampler=sampler_batch, num_workers=args.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilize the tensor holder here.\n",
    "im_data = torch.FloatTensor(1)\n",
    "im_info = torch.FloatTensor(1)\n",
    "num_boxes = torch.LongTensor(1)\n",
    "gt_boxes = torch.FloatTensor(1)\n",
    "\n",
    "# ship to cuda\n",
    "if args.cuda:\n",
    "im_data = im_data.cuda()\n",
    "im_info = im_info.cuda()\n",
    "num_boxes = num_boxes.cuda()\n",
    "gt_boxes = gt_boxes.cuda()\n",
    "\n",
    "# make variable\n",
    "im_data = Variable(im_data)\n",
    "im_info = Variable(im_info)\n",
    "num_boxes = Variable(num_boxes)\n",
    "gt_boxes = Variable(gt_boxes)\n",
    "\n",
    "if args.cuda:\n",
    "cfg.CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasterRCNN = vgg16(imdb.classes, pretrained=True, class_agnostic=args.class_agnostic)\n",
    "fasterRCNN.create_architecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = cfg.TRAIN.LEARNING_RATE\n",
    "lr = args.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  params = []\n",
    "  for key, value in dict(fasterRCNN.named_parameters()).items():\n",
    "    if value.requires_grad:\n",
    "      if 'bias' in key:\n",
    "        params += [{'params':[value],'lr':lr*(cfg.TRAIN.DOUBLE_BIAS + 1), \\\n",
    "                'weight_decay': cfg.TRAIN.BIAS_DECAY and cfg.TRAIN.WEIGHT_DECAY or 0}]\n",
    "      else:\n",
    "        params += [{'params':[value],'lr':lr, 'weight_decay': cfg.TRAIN.WEIGHT_DECAY}]\n",
    "\n",
    "  if args.cuda:\n",
    "    fasterRCNN.cuda()\n",
    "      \n",
    "  if args.optimizer == \"adam\":\n",
    "    lr = lr * 0.1\n",
    "    optimizer = torch.optim.Adam(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  if args.resume:\n",
    "    load_name = os.path.join(output_dir,\n",
    "      'faster_rcnn_{}_{}_{}.pth'.format(args.checksession, args.checkepoch, args.checkpoint))\n",
    "    print(\"loading checkpoint %s\" % (load_name))\n",
    "    checkpoint = torch.load(load_name)\n",
    "    args.session = checkpoint['session']\n",
    "    args.start_epoch = checkpoint['epoch']\n",
    "    fasterRCNN.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    if 'pooling_mode' in checkpoint.keys():\n",
    "      cfg.POOLING_MODE = checkpoint['pooling_mode']\n",
    "    print(\"loaded checkpoint %s\" % (load_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters_per_epoch = int(train_size / args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.use_tfboard:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    logger = SummaryWriter(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.start_epoch, args.max_epochs + 1):\n",
    "    # setting to train mode\n",
    "    fasterRCNN.train()\n",
    "    loss_temp = 0\n",
    "    start = time.time()\n",
    "\n",
    "    if epoch % (args.lr_decay_step + 1) == 0:\n",
    "        adjust_learning_rate(optimizer, args.lr_decay_gamma)\n",
    "        lr *= args.lr_decay_gamma\n",
    "\n",
    "    data_iter = iter(dataloader)\n",
    "    for step in range(iters_per_epoch):\n",
    "      data = next(data_iter)\n",
    "      with torch.no_grad():\n",
    "              im_data.resize_(data[0].size()).copy_(data[0])\n",
    "              im_info.resize_(data[1].size()).copy_(data[1])\n",
    "              gt_boxes.resize_(data[2].size()).copy_(data[2])\n",
    "              num_boxes.resize_(data[3].size()).copy_(data[3])\n",
    "\n",
    "      fasterRCNN.zero_grad()\n",
    "      rois, cls_prob, bbox_pred, \\\n",
    "      rpn_loss_cls, rpn_loss_box, \\\n",
    "      RCNN_loss_cls, RCNN_loss_bbox, \\\n",
    "      rois_label = fasterRCNN(im_data, im_info, gt_boxes, num_boxes)\n",
    "\n",
    "      loss = rpn_loss_cls.mean() + rpn_loss_box.mean() \\\n",
    "           + RCNN_loss_cls.mean() + RCNN_loss_bbox.mean()\n",
    "      loss_temp += loss.item()\n",
    "\n",
    "      # backward\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "        clip_gradient(fasterRCNN, 10.)\n",
    "      optimizer.step()\n",
    "\n",
    "      if step % args.disp_interval == 0:\n",
    "        end = time.time()\n",
    "        if step > 0:\n",
    "          loss_temp /= (args.disp_interval + 1)\n",
    "\n",
    "        if args.mGPUs:\n",
    "          loss_rpn_cls = rpn_loss_cls.mean().item()\n",
    "          loss_rpn_box = rpn_loss_box.mean().item()\n",
    "          loss_rcnn_cls = RCNN_loss_cls.mean().item()\n",
    "          loss_rcnn_box = RCNN_loss_bbox.mean().item()\n",
    "          fg_cnt = torch.sum(rois_label.data.ne(0))\n",
    "          bg_cnt = rois_label.data.numel() - fg_cnt\n",
    "        else:\n",
    "          loss_rpn_cls = rpn_loss_cls.item()\n",
    "          loss_rpn_box = rpn_loss_box.item()\n",
    "          loss_rcnn_cls = RCNN_loss_cls.item()\n",
    "          loss_rcnn_box = RCNN_loss_bbox.item()\n",
    "          fg_cnt = torch.sum(rois_label.data.ne(0))\n",
    "          bg_cnt = rois_label.data.numel() - fg_cnt\n",
    "\n",
    "        print(\"[session %d][epoch %2d][iter %4d/%4d] loss: %.4f, lr: %.2e\" \\\n",
    "                                % (args.session, epoch, step, iters_per_epoch, loss_temp, lr))\n",
    "        print(\"\\t\\t\\tfg/bg=(%d/%d), time cost: %f\" % (fg_cnt, bg_cnt, end-start))\n",
    "        print(\"\\t\\t\\trpn_cls: %.4f, rpn_box: %.4f, rcnn_cls: %.4f, rcnn_box %.4f\" \\\n",
    "                      % (loss_rpn_cls, loss_rpn_box, loss_rcnn_cls, loss_rcnn_box))\n",
    "        if args.use_tfboard:\n",
    "          info = {\n",
    "            'loss': loss_temp,\n",
    "            'loss_rpn_cls': loss_rpn_cls,\n",
    "            'loss_rpn_box': loss_rpn_box,\n",
    "            'loss_rcnn_cls': loss_rcnn_cls,\n",
    "            'loss_rcnn_box': loss_rcnn_box\n",
    "          }\n",
    "          logger.add_scalars(\"logs_s_{}/losses\".format(args.session), info, (epoch - 1) * iters_per_epoch + step)\n",
    "\n",
    "        loss_temp = 0\n",
    "        start = time.time()\n",
    "\n",
    "\n",
    "    save_name = os.path.join(output_dir, 'faster_rcnn_{}_{}_{}.pth'.format(args.session, epoch, step))\n",
    "    save_checkpoint({\n",
    "      'session': args.session,\n",
    "      'epoch': epoch + 1,\n",
    "      'model': fasterRCNN.module.state_dict() if args.mGPUs else fasterRCNN.state_dict(),\n",
    "      'optimizer': optimizer.state_dict(),\n",
    "      'pooling_mode': cfg.POOLING_MODE,\n",
    "      'class_agnostic': args.class_agnostic,\n",
    "    }, save_name)\n",
    "    print('save model: {}'.format(save_name))\n",
    "\n",
    "    if args.use_tfboard:\n",
    "    logger.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
