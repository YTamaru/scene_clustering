{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import random as rn\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflowの乱数シード固定(再現性の担保)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(7)\n",
    "rn.seed(7)\n",
    "\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "\n",
    "tf.set_random_seed(7)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像データ取り込み\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data/'\n",
    "datalist = pd.read_csv(os.path.join(DATA_FOLDER, 'frames_data.csv'), names=[\"img_path\", \"l_class\", 's_class','timestamp'])\n",
    "datalist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_classlist = ['4gokan', '5gokan', '5gokan-denkisogokan', '5gokan-mediacenter'\n",
    "                    '8gokan', 'denkisogokan', 'lab', 'lab-lounge', 'lounge']\n",
    "s_classlist = ['4gokan_inside', '4gokan_outside', '5gokan-denkisogokan', '5gokan-mediacenter',\n",
    "'5gokan_1F', '5gokan_2F', '5gokan_3F', '5gokan_ent_east', '5gokan_lounge',\n",
    "'5gokan_out_east', '5gokan_parking', '5gokan_smoking', '5gokan_stairs_cnt',\n",
    "'5gokan_stairs_west', '8gokan_1F', '8gokan_ent_north', '8gokan_ent_south',\n",
    "'denkisogokan_2F', 'denkisogokan_3F', 'denkisogokan_4F', 'denkisogokan_elevator',\n",
    "'denkisogokan_lounge', 'denkisogokan_stairs', 'lab-lounge', 'lab_bs_cnt',\n",
    "'lab_corner', 'lab_desk', 'lab_desk_table', 'lab_ent', 'lab_printer',\n",
    "'lab_table', 'lab_wb_cnt', 'lab_wb_ent', 'lounge']\n",
    "num_l_class =len(l_classlist)\n",
    "num_s_class = len(s_classlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_s_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = datalist.drop(['s_class','timestamp'], axis=1)\n",
    "dfl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl.groupby('l_class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = datalist.drop(['l_class', 'timestamp'], axis=1)\n",
    "dfs.groupby('s_class').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "le = LabelEncoder()\n",
    "le.fit(dfs.s_class)\n",
    "dfs[\"labels\"] = le.transform(dfs.s_class)\n",
    "dfs.groupby('labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "cor_table = dfs.groupby('labels').s_class.unique()\n",
    "cor_table = pd.DataFrame(cor_table)\n",
    "cor_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "cor_table.to_csv('cor_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "dfs = dfs.drop(['s_class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "x = []\n",
    "for i in range(len(dfs.img_path)):\n",
    "    image = img_to_array(load_img(dfs.img_path[i], target_size=(224,224)))\n",
    "    x.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "y = dfs.labels\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "#正規化\n",
    "x = np.array(x, dtype='float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "#np.array形式のデータを保存　x, y\n",
    "np.save(file='x.npy', arr=x)\n",
    "np.save(file='y.npy', arr=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, yをload\n",
    "x = np.load(file='x.npy')\n",
    "y = np.load(file='y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test & validation set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_valid, y, y_valid = train_test_split(x,y, random_state=42, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA(探索的データ解析)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,18))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05, wspace=0.05)\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(x[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN(keras NotPretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Activation, add, Add, Dropout, BatchNormalization, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(224,224,3))\n",
    "x1 = Conv2D(64, kernel_size=(3,3), activation='relu')(inputs)\n",
    "x2 = Conv2D(64, kernel_size=(3,3), activation='relu')(x1)\n",
    "x3 = MaxPooling2D(pool_size=(2,2))(x2)\n",
    "x4 = Conv2D(128, kernel_size=(3,3), activation='relu')(x3)\n",
    "x5 = Conv2D(128, kernel_size=(3,3), activation='relu')(x4)\n",
    "x6 = MaxPooling2D(pool_size=(2,2))(x5)\n",
    "x7 = Flatten()(x6)\n",
    "prediction = Dense(num_s_class, activation='softmax')(x7)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=prediction)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto')\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('omni_video.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = GlobalMaxPooling2D(name='Conv2D_1')(x1)\n",
    "feature2 = GlobalMaxPooling2D(name='Conv2D_1')(x2)\n",
    "feature3 = GlobalMaxPooling2D(name='Conv2D_1')(x3)\n",
    "feature4 = GlobalMaxPooling2D(name='Conv2D_1')(x4)\n",
    "feature5 = GlobalMaxPooling2D(name='Conv2D_1')(x5)\n",
    "feature6 = GlobalMaxPooling2D(name='Conv2D_1')(x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_model1 = Model(inputs=model.input, outputs=feature1)\n",
    "hidden_model2 = Model(inputs=model.input, outputs=feature2)\n",
    "hidden_model3 = Model(inputs=model.input, outputs=feature3)\n",
    "hidden_model4 = Model(inputs=model.input, outputs=feature4)\n",
    "hidden_model5 = Model(inputs=model.input, outputs=feature5)\n",
    "hidden_model6= Model(inputs=model.input, outputs=feature6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # 層化抽出法(Stratified sampling)&KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "cvscores = []\n",
    "#Stratified KFoldはlabel encoding化した整数ベクトルでないともちいることができない\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #One-hot化　CNNに入出力できるように整形\n",
    "    y_train = np_utils.to_categorical(y_train, num_s_class)\n",
    "    y_test = np_utils.to_categorical(y_test, num_s_class)\n",
    "    model.fit(x_train, y_train, verbose=1, batch_size=batch_size, epochs=n_epochs,\n",
    "              callbacks=[early_stopping], validation_split=0.2)\n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ validation_dataを用意しないとval_lossを計算できない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.sparse.csgraph import connected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = np_utils.to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_valid)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmx = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(cmx, annot=True)\n",
    "plt.show()\n",
    "print('accuracy: {}'.format(accuracy_score\n",
    "(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_table = pd.read_csv('cor_table.csv')\n",
    "print(cor_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中間層特徴量の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = hidden_model1.predict(x_train)\n",
    "hidden2 = hidden_model2.predict(x_train)\n",
    "hidden3 = hidden_model3.predict(x_train)\n",
    "hidden4 = hidden_model4.predict(x_train)\n",
    "hidden5 = hidden_model5.predict(x_train)\n",
    "hidden6 = hidden_model6.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(hidden1.shape)\n",
    "print(hidden2.shape)\n",
    "print(hidden3.shape)\n",
    "print(hidden4.shape)\n",
    "print(hidden5.shape)\n",
    "print(hidden6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#標準化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(hidden1)\n",
    "hidden1 = scaler.transform(hidden1)\n",
    "scaler.fit(hidden2)\n",
    "hidden1 = scaler.transform(hidden2)\n",
    "scaler.fit(hidden3)\n",
    "hidden1 = scaler.transform(hidden3)\n",
    "scaler.fit(hidden4)\n",
    "hidden1 = scaler.transform(hidden4)\n",
    "scaler.fit(hidden5)\n",
    "hidden1 = scaler.transform(hidden5)\n",
    "scaler.fit(hidden6)\n",
    "hidden1 = scaler.transform(hidden6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_name = 'jet'\n",
    "cmap = plt.get_cmap(cm_name, num_s_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hotから整数値ベクトルに変換\n",
    "y_train_vec = []\n",
    "for i in range(len(y_train)):\n",
    "    y_train_vec.append(np.argmax(y_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1層目の特徴ベクトル(Conv2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = pca.fit_transform(hidden1)\n",
    "#　主成分分析の例(1層目)\n",
    "df_feature1 = pd.DataFrame(feature1)\n",
    "print(df_feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature1[:,0],feature1[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(hidden1)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2層目の特徴ベクトル (Conv2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2 = pca.fit_transform(hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature2[:,0],feature2[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(hidden2)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3層目の特徴ベクトル (MaxPooling2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature3 = pca.fit_transform(hidden3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature3[:,0],feature3[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(hidden3)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4層目の特徴ベクトル (Conv2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature4 = pca.fit_transform(hidden4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(feature4[:,0],feature4[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(hidden4)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5層目の特徴ベクトル (Conv2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature5 = pca.fit_transform(hidden5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature5[:,0],feature5[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(hidden5)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6層目の特徴ベクトル(MaxPooling2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature6 = pca.fit_transform(hidden6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature6[:,0],feature6[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.fit(hidden6)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "for i in range(num_s_class):\n",
    "    true.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "grad_last_conv = model.get_layer(\"conv2d_3\")\n",
    "model_output = model.output[:,0]\n",
    "grads = K.gradients(model_output, grad_last_conv.output)[0]\n",
    "pooled_grads = K.mean(grads, axis=(0,1,2))\n",
    "iterate = K.function([model.input], [pooled_grads, grad_last_conv.output[0]])\n",
    "\n",
    "for n in range(len(grad_test_img_path)):\n",
    "    img_keras = image.load_img(grad_test_img_path[n], target_size=(224, 224))\n",
    "    img_tensor = image.img_to_array(img_keras)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "    predicts = model.predict(img_tensor)\n",
    "    s_class_num = np.argmax(predicts)\n",
    "    pred.append(s_class_num)\n",
    "    img_tensor /= 255.\n",
    "    pooled_grads_val, conv_output_val = iterate([img_tensor])\n",
    "    for i in range(pooled_grads_val.shape[0]):\n",
    "        conv_output_val[:, :, i] *= pooled_grads_val[i]\n",
    "    heatmap = np.mean(conv_output_val, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    img = cv2.imread(grad_test_img_path[n])\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = heatmap * 0.4 + img\n",
    "    save_dir = '../data/gradcam_img/selfCNN/'+s_classlist[n]\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\t# Make a directory\n",
    "    #保存先ディレクトリ名はその画像のクラス，画像の予測値を画像の名前に書き込む\n",
    "    cv2.imwrite(save_dir+'/heatmap_pred_'+s_classlist[s_class_num]+'.jpg', superimposed_img)\n",
    "    print('Saved: ', save_dir+'/heatmap_pred_'+s_classlist[s_class_num]+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmx = confusion_matrix(true, pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(cmx, annot=True)\n",
    "plt.ylabel(\"truth\")\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_table = pd.read_csv('cor_table.csv')\n",
    "print(cor_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16(weight=\"ImageNet\", include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top(全結合層など)はデフォルトだとImageNetの全クラス数1000での出力になるので，\n",
    "自作のアーキテクチャを使用する\n",
    "top以外のモデルの重みは(ImageNetで)固定しない→学習をする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning(Flozen(Not training vgg layers))\n",
    "training all layers -> acc: 0.1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(224,224,3))\n",
    "x1 = vgg_model(inputs)\n",
    "x2 = Flatten()(x1)\n",
    "x3 = Dense(256, activation='relu')(x2)\n",
    "prediction = Dense(num_s_class, activation='softmax')(x3)\n",
    "full_model = Model(inputs=inputs, outputs=prediction)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto')\n",
    "for layer in vgg_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "full_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "cvscores = []\n",
    "#Stratified KFoldはlabel encoding化した整数ベクトルでないともちいることができない\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #One-hot化　CNNに入出力できるように整形\n",
    "    y_train = np_utils.to_categorical(y_train, num_s_class)\n",
    "    y_test = np_utils.to_categorical(y_test, num_s_class)\n",
    "    full_model.fit(x_train, y_train, verbose=1, batch_size=batch_size, epochs=n_epochs,\n",
    "              callbacks=[early_stopping], validation_split=0.2)\n",
    "    scores = full_model.evaluate(x_test, y_test)\n",
    "    print(\"%s: %.2f%%\" % (full_model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = full_model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_valid)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmx = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(cmx, annot=True)\n",
    "plt.show()\n",
    "print('accuracy: {}'.format(accuracy_score\n",
    "(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_table = pd.read_csv('cor_table.csv')\n",
    "print(cor_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中間層特徴量の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = vgg_model.get_layer('block1_pool').output\n",
    "output1 = GlobalMaxPooling2D()(x1)\n",
    "block_model1 = Model(inputs=vgg_model.input, outputs=output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = vgg_model.get_layer('block2_pool').output\n",
    "output2 = GlobalMaxPooling2D()(x2)\n",
    "block_model2 = Model(inputs=vgg_model.input, outputs=output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = vgg_model.get_layer('block3_pool').output\n",
    "output3 = GlobalMaxPooling2D()(x3)\n",
    "block_model3 = Model(inputs=vgg_model.input, outputs=output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4 = vgg_model.get_layer('block4_pool').output\n",
    "output4 = GlobalMaxPooling2D()(x4)\n",
    "block_model4 = Model(inputs=vgg_model.input, outputs=output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5 = vgg_model.get_layer('block5_pool').output\n",
    "output5 = GlobalMaxPooling2D()(x5)\n",
    "block_model5 = Model(inputs=vgg_model.input, outputs=output5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = block_model1.predict(x_train)\n",
    "block2 = block_model2.predict(x_train)\n",
    "block3 = block_model3.predict(x_train)\n",
    "block4 = block_model4.predict(x_train)\n",
    "block5 = block_model5.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(block1.shape)\n",
    "print(block2.shape)\n",
    "print(block3.shape)\n",
    "print(block4.shape)\n",
    "print(block5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# block1の特徴ベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = pca.fit_transform(block1)\n",
    "#　主成分分析の例(1層目)\n",
    "df_feature1 = pd.DataFrame(feature1)\n",
    "print(df_feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature1[:,0],feature1[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(block1)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# block2の特徴ベクトル "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2 = pca.fit_transform(block2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature2[:,0],feature2[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(block2)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# block3の特徴ベクトル "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature3 = pca.fit_transform(block3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature3[:,0],feature3[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(block3)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# block4の特徴ベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature4 = pca.fit_transform(block4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature4[:,0],feature4[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(block4)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# block5の特徴ベクトル "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature5 = pca.fit_transform(block5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature5[:,0],feature5[:,1],marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(block5)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure().add_subplot(111, projection='3d')\n",
    "ax.scatter(feature5[:,0],feature5[:,1], feature5[:,3], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_zlabel(\"PC3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception v3 (Pretrained ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(224,224,3))\n",
    "x1 = base_model(inputs)\n",
    "x2 = Flatten()(x1)\n",
    "x3 = Dense(256, activation='relu')(x2)\n",
    "prediction = Dense(num_s_class, activation='softmax')(x3)\n",
    "full_model = Model(inputs=inputs, outputs=prediction)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto')\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "    if layer.name.startswith('batch_normalization'):\n",
    "        layer.trainable = True\n",
    "full_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top(全結合層など)はデフォルトだとImageNetの全クラス数1000での出力になるので，\n",
    "自作のアーキテクチャを使用する\n",
    "top以外のモデルの重みは(ImageNetで)固定しない→学習をする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning(Flozen(Not training InceptionV3 layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "cvscores = []\n",
    "#Stratified KFoldはlabel encoding化した整数ベクトルでないともちいることができない\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #One-hot化　CNNに入出力できるように整形\n",
    "    y_train = np_utils.to_categorical(y_train, num_s_class)\n",
    "    y_test = np_utils.to_categorical(y_test, num_s_class)\n",
    "    full_model.fit(x_train, y_train, verbose=1, batch_size=batch_size, epochs=n_epochs,\n",
    "              callbacks=[early_stopping], validation_split=0.2)\n",
    "    scores = full_model.evaluate(x_test, y_test)\n",
    "    print(\"%s: %.2f%%\" % (full_model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = full_model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_valid)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmx = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(cmx, annot=True)\n",
    "plt.show()\n",
    "print('accuracy: {}'.format(accuracy_score\n",
    "(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_table = pd.read_csv('cor_table.csv')\n",
    "print(cor_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  最終層の特徴ベクトル "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_last = base_model.get_layer('mixed10').output\n",
    "output_last = GlobalMaxPooling2D()(x_last)\n",
    "model_last = Model(inputs=base_model.input, outputs=output_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_feature = model_last.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(last_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_pca = pca.fit_transform(last_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(last_pca[:,0],last_pca[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure().add_subplot(111, projection='3d')\n",
    "ax.scatter(last_pca[:,0],last_pca[:,1], last_pca[:,3], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_zlabel(\"PC3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(last_feature)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非線形成分を考慮した次元削減\n",
    "PCAは線形成分に注目した次元削減方法なので，非線形性を考慮した手法を試す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中間層の特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元画像(x_train)についてRandom Forestを行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像データそのままだとRandomForestできないのでGlobalMaxPooling2Dだけかける\n",
    "x_train_pool = GlobalMaxPooling2D()(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf.fit(x_train_pool, y_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rnd_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = np.array(y_pred_rf)\n",
    "y_true = np.array(y_test)\n",
    "y_pred_rf = np.argmax(y_pred_rf, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_rf.shape)\n",
    "print(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmx = confusion_matrix(y_true, y_pred_rf)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(cmx, annot=True)\n",
    "plt.show()\n",
    "print('accuracy: {}'.format(accuracy_score\n",
    "(y_true, y_pred_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rnd_clf.feature_importances_\n",
    "print(feature_importance)\n",
    "print(\"shape:\", len(feature_importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InceptionV3の最終層の特徴量についてRandom Forestを行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(last_feature, y_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_feature_importance = rnd_clf.feature_importances_\n",
    "print(last_feature_importance)\n",
    "print(\"shape:\", len(last_feature_importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(last_feature_importance.reshape(32, 64), cmap=\"Reds\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoVW→k-means→PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 (keras NotPretrained ImageNet)<br>\n",
    "include_top: ネットワークの出力層側にある全結合層を含むかどうか．<br>\n",
    "weights: None (ランダム初期化) か 'imagenet' (ImageNetで学習した重み) の一方．<br>\n",
    "input_tensor: モデルの入力画像として利用するためのオプションのKerasテンソル (つまり，layers.Input()の出力)<br>\n",
    "input_shape: オプショナルなshapeのタプル，include_topがFalseの場合のみ指定可能 (そうでないときは入力のshapeは(224, 224, 3) ('channels_last'データフォーマットのとき) か (3, 224, 224) ('channels_first'データフォーマットのとき) )．正確に3つの入力チャンネルをもつ必要があり，width と height は197以上にする必要があります．例えば(200, 200, 3)は有効値．<br>\n",
    "pooling: 特徴量抽出のためのオプショナルなpooling mode，include_topがFalseの場合のみ指定可能．<br>\n",
    "    None：モデルの出力が，最後のconvolutional layerの4階テンソルであることを意味しています．<br>\n",
    "    'avg'：最後のconvolutional layerの出力にglobal average poolingが適用されることで，モデルの出力が2階テンソルになることを意味しています．<br>\n",
    "    'max'：global max poolingが適用されることを意味します．<br>\n",
    "classes: 画像のクラス分類のためのオプショナルなクラス数，include_topがTrueかつweightsが指定されていない場合のみ指定可能<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
