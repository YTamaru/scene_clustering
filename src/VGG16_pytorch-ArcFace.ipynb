{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skorch\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from torch.utils import data\n",
    "from models import *\n",
    "from utils import Visualizer, view_model\n",
    "import random\n",
    "import time\n",
    "from config.config import Config\n",
    "from torch.nn import DataParallel\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/home/tamaru/scene_categorize/main/data/'\n",
    "csv_path = os.path.join(DATA_FOLDER, 'resized_data.csv')\n",
    "datalist = pd.read_csv(csv_path, names=[\"img_path\", \"l_class\", 's_class'])\n",
    "datalist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = datalist.drop(['l_class'], axis=1)\n",
    "dfs.groupby('s_class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.img_path.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_df = pd.read_csv(\"/home/tamaru/scene_categorize/main/data/inpainting_data.csv\", names=[\"img_path\", \"l_class\", 's_class'])\n",
    "heatmap_df = heatmap_df.drop(['l_class'], axis=1)\n",
    "heatmap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder() \n",
    "le.fit(dfs.s_class) \n",
    "dfs[\"labels\"] = le.transform(dfs.s_class) \n",
    "dfs.groupby('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_table = dfs.groupby('labels').s_class.unique() \n",
    "cor_table = pd.DataFrame(cor_table) \n",
    "num_s_class = len(cor_table)\n",
    "cor_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_df['labels'] = le.transform(heatmap_df.s_class)\n",
    "heatmap_table = heatmap_df.groupby('labels').s_class.unique()\n",
    "heatmap_df= heatmap_df.drop(['s_class'], axis=1)\n",
    "heatmap_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.drop(['s_class'], axis=1)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainデータ, testデータの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(dfs, test_size=0.2, random_state=42, stratify=dfs.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42, stratify=train_data.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像の前処理を定義\n",
    "data_transforms = {\n",
    "    'data': transforms.Compose([\n",
    "        transforms.Resize(224), #いらない\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ])\n",
    "}\n",
    "#正規化をしない処理\n",
    "to_tensor_transforms = transforms.Compose([\n",
    "    transforms.Resize(224), #いらない\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "        \n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        #前処理クラスの指定\n",
    "        self.transform = transform\n",
    "        #pandasでcsvデータの読み出し\n",
    "        #画像とラベルの一覧を保持するリスト\n",
    "        self.images = np.array(dataframe.img_path).tolist()\n",
    "        self.labels = np.array(dataframe.labels).tolist()\n",
    "        self.root_dir = root_dir\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #dataframeから画像へのパスとラベルを読み出す\n",
    "        label = self.labels[idx]\n",
    "        img = self.images[idx]\n",
    "        #画像の読み込み\n",
    "        with open(img, 'rb') as f:\n",
    "            image = Image.open(f)\n",
    "            image = image.convert('RGB')\n",
    "            image = image.resize((224,224))\n",
    "        #画像への処理\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(dataframe=train_data, root_dir=\"../data/insta_frames\", transform=data_transforms['data'])\n",
    "val_set = CustomDataset(dataframe=val_data, root_dir=\"../data/insta_frames\", transform=data_transforms['data'])\n",
    "test_set = CustomDataset(dataframe=test_data, root_dir=\"../data/insta_frames\", transform=data_transforms['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaderのcollate_fnはバッチ内のtensorのshapeをすべて同じにする必要がある\n",
    "# 自分で指定してエラーが起きないようにする\n",
    "def my_collate_fn(batch):\n",
    "    # datasetの出力が\n",
    "    # [image, target] = dataset[batch_idx]\n",
    "    # の場合.\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image, label in batch:\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "    images = torch.stack(images,dim=0)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=16, shuffle=True, num_workers=6)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set, batch_size=16, shuffle=False, num_workers=6)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=16, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_set = CustomDataset(dataframe=heatmap_df, root_dir=\"../data/inpainting_data\", transform=data_transforms['data'])\n",
    "heatmap_loader = torch.utils.data.DataLoader(dataset=heatmap_set, batch_size=1, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ネットワークの定義\n",
    "vgg16 finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = num_s_class\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = models.vgg16(pretrained=True, progress=True)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パラメータ凍結と採取層クラス数変更\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "#最終層をnum_s_classクラス用に変更\n",
    "num_ftrs = net.classifier[6].in_features\n",
    "opt = Config()\n",
    "# net.avgpool = None\n",
    "net.classifier[6] = nn.Linear(num_ftrs, 512)\n",
    "metric_fc = ArcMarginProduct(512, num_classes, s=10, m=0.1, easy_margin=opt.easy_margin)\n",
    "#最適化関数\n",
    "criterion = FocalLoss(gamma=2)\n",
    "optimizer = optim.SGD([{'params': net.parameters()}, {'params': metric_fc.parameters()}],lr=opt.lr, weight_decay=opt.weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=opt.lr_step, gamma=0.1)\n",
    "net = net.to(device)\n",
    "metric_fc.to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#学習率の変更\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validationを行いたい...\n",
    "#Early Stopping を行いたい\n",
    "\n",
    "num_epochs = 50\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    \n",
    "    #train\n",
    "    net.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        #view()での変換をしない\n",
    "        images, labels = images.to(device), labels.to(device).long()\n",
    "        \n",
    "        features = net(images)\n",
    "        outputs = metric_fc(features, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        iters = epoch * len(train_loader) + i\n",
    "\n",
    "        if iters % opt.print_freq == 0:\n",
    "            outputs = outputs.data.cpu().numpy()\n",
    "            outputs = np.argmax(outputs, axis=1)\n",
    "            labels = labels.data.cpu().numpy()\n",
    "            # print(output)\n",
    "            # print(label)\n",
    "            acc = np.mean((outputs == labels).astype(int))\n",
    "            speed = opt.print_freq / (time.time() - start)\n",
    "            time_str = time.asctime(time.localtime(time.time()))\n",
    "            print('{} train epoch {} iter {} {} iters/s loss {} acc {}'.format(time_str, epoch, i, speed, loss.item(), acc))\n",
    "            if opt.display:\n",
    "                visualizer = Visualizer()\n",
    "                visualizer.display_current_results(iters, loss.item(), name='train_loss')\n",
    "                visualizer.display_current_results(iters, acc, name='train_acc')\n",
    "\n",
    "            start = time.time()\n",
    "            \n",
    "#         train_loss += loss.item()\n",
    "# #         train_acc += (outputs.max(1)[1]==labels).sum().item()\n",
    "#         outputs = outputs.data.cpu().numpy()\n",
    "#         outputs = np.argmax(outputs, axis=1)\n",
    "#         labels = labels.data.cpu().numpy()\n",
    "#         acc = np.mean((outputs==labels).astype(int))\n",
    "#         train_acc += acc\n",
    "        \n",
    "#     avg_train_loss = train_loss/len(train_loader.dataset)\n",
    "#     avg_train_acc = train_acc/len(train_loader.dataset)\n",
    "    \n",
    "#     #validation\n",
    "#     net.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in val_loader:\n",
    "#             #view()での変換をしない\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.to(device).long()\n",
    "#             features = net(images)\n",
    "#             outputs = metric_fc(features, labels)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             val_loss += loss.item()\n",
    "# #             val_acc += (outputs.max(1)[1]==labels).sum().item()\n",
    "#             outputs = outputs.data.cpu().numpy()\n",
    "#             outputs = np.argmax(outputs, axis=1)\n",
    "#             labels = labels.data.cpu().numpy()\n",
    "#             print(outputs==labels)\n",
    "#             acc = np.mean((outputs==labels).astype(int))\n",
    "#             val_acc += acc\n",
    "#     avg_val_loss = val_loss/len(val_loader.dataset)\n",
    "#     avg_val_acc = val_acc/len(val_loader.dataset)\n",
    "    \n",
    "#     print('Epoch [{}/{}], Loss: {loss:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}'.format(epoch+1, num_epochs, i+1, loss=avg_train_loss, val_loss=avg_val_loss, val_acc=avg_val_acc))\n",
    "#     train_loss_list.append(avg_train_loss)\n",
    "#     train_acc_list.append(avg_train_acc)\n",
    "#     val_loss_list.append(avg_val_loss)\n",
    "#     val_acc_list.append(avg_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, validationのloss acc のグラフを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(num_epochs), train_loss_list, color='blue', linestyle='-', label='train_loss')\n",
    "plt.plot(range(num_epochs), val_loss_list, color='green', linestyle='--', label='val_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.grid()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(num_epochs), train_acc_list, color='blue', linestyle='-', label='train_acc')\n",
    "plt.plot(range(num_epochs), val_acc_list, color='green', linestyle='--', label='test_acc')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.title('Training and validation acc')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAMの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCam:\n",
    "    def __init__(self, model):\n",
    "        self.model = model.eval()\n",
    "        self.feature = None\n",
    "        self.gradient = None\n",
    "    \n",
    "    def save_gradient(self, grad):\n",
    "        self.gradient = grad\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        image_size = (x.size(-1), x.size(-2))\n",
    "        feature_maps =[]\n",
    "        \n",
    "        for i in range(x.size(0)):\n",
    "            img = x[i].data.cpu().numpy() #GPU上のTensorはcpuに移さないとnumpyに変換できない\n",
    "            img = img - np.min(img)\n",
    "            if np.max(img) != 0:\n",
    "                img = img / np.max(img)\n",
    "            \n",
    "            feature = x[i].unsqueeze(0)\n",
    "            \n",
    "            for name, module in self.model.named_children():\n",
    "                if name == 'clasifier':\n",
    "                    feature = feature.view(feature.size(0), -1)\n",
    "                feature = module(feature)\n",
    "                if name == 'features':\n",
    "                    feature.register_hook(self.save_gradient)\n",
    "                    self.feature = feature\n",
    "                    \n",
    "            classes = F.sigmoid(feature)\n",
    "            one_hot, _ = classes.max(dim=-1)\n",
    "            self.model.zero_grad()\n",
    "            one_hot.backward()\n",
    "            \n",
    "            weight = self.gradient.mean(dim=-1, keepdim=True).mean(dim=-2, keepdim=True)\n",
    "            \n",
    "            mask = F.relu((weight*self.feature).sum(dim=1)).squeeze(0)\n",
    "            mask = cv2.resize(mask.data.cpu().numpy(), image_size)\n",
    "            mask = mask - np.min(mask)\n",
    "            \n",
    "            if np.max(mask) != 0:\n",
    "                mask = mask/np.max(mask)\n",
    "                \n",
    "            feature_map = np.float32(cv2.applyColorMap(np.uint8(255*mask), cv2.COLORMAP_JET))\n",
    "            cam = feature_map + np.float32((np.uint8(img.transpose((1,2,0))*225)))\n",
    "            cam = cam - np.min(cam)\n",
    "            \n",
    "            if np.max(cam) != 0:\n",
    "                cam = cam/np.max(cam)\n",
    "                \n",
    "            feature_maps.append(transforms.ToTensor()(cv2.cvtColor(np.uint8(225*cam), cv2.COLOR_BGR2RGB)))\n",
    "            \n",
    "        feature_maps = torch.stack(feature_maps)\n",
    "        \n",
    "        return feature_maps\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cam_test_img_path)):\n",
    "    #入力画像の読み込み\n",
    "    cam_test_img = Image.open(cam_test_img_path[i])\n",
    "    cam_img_tensor = (data_transforms['data']((cam_test_img))).unsqueeze(dim=0)\n",
    "    \n",
    "    cam_img_tensor = cam_img_tensor.to(device)\n",
    "    \n",
    "    img_size = cam_test_img.size\n",
    "    #grad-camによる予測根拠可視化\n",
    "    gradcam = GradCam(net)\n",
    "    \n",
    "    feature_image = gradcam(cam_img_tensor).squeeze(dim=0)\n",
    "    feature_image = transforms.ToPILImage()(feature_image)\n",
    "    \n",
    "    pred_idx = net(cam_img_tensor).max(1)[1]\n",
    "                      \n",
    "    save_dir = '../data/gradcam_img/VGG16/'+s_classlist[i]\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\t# Make a directory\n",
    "    #保存先ディレクトリ名はその画像のクラス，画像の予測値を画像の名前に書き込む\n",
    "    cv2.imwrite(save_dir+'/heatmap_pred_'+s_classlist[pred_idx]+'.jpg', superimposed_img)\n",
    "    print('Saved: ', save_dir+'/heatmap_pred_'+s_classlist[pred_idx]+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
