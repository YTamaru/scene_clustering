{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import random as rn\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflowの乱数シード固定(再現性の担保)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(7)\n",
    "rn.seed(7)\n",
    "\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "\n",
    "tf.set_random_seed(7)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像データ取り込み\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data/'\n",
    "datalist = pd.read_csv(os.path.join(DATA_FOLDER, 'frames_data.csv'), names=[\"img_path\", \"l_class\", 's_class','timestamp'])\n",
    "datalist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_classlist = ['4gokan', '5gokan', '5gokan-denkisogokan', '5gokan-mediacenter'\n",
    "                    '8gokan', 'denkisogokan', 'lab', 'lab-lounge', 'lounge']\n",
    "s_classlist = ['4gokan_inside', '4gokan_outside', '5gokan-denkisogokan', '5gokan-mediacenter',\n",
    "'5gokan_1F', '5gokan_2F', '5gokan_3F', '5gokan_ent_east', '5gokan_lounge',\n",
    "'5gokan_out_east', '5gokan_parking', '5gokan_smoking', '5gokan_stairs_cnt',\n",
    "'5gokan_stairs_west', '8gokan_1F', '8gokan_ent_north', '8gokan_ent_south',\n",
    "'denkisogokan_2F', 'denkisogokan_3F', 'denkisogokan_4F', 'denkisogokan_elevator',\n",
    "'denkisogokan_lounge', 'denkisogokan_stairs', 'lab-lounge', 'lab_bs_cnt',\n",
    "'lab_corner', 'lab_desk', 'lab_desk_table', 'lab_ent', 'lab_printer',\n",
    "'lab_table', 'lab_wb_cnt', 'lab_wb_ent', 'lounge']\n",
    "num_l_class =len(l_classlist)\n",
    "num_s_class = len(s_classlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_s_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = datalist.drop(['s_class','timestamp'], axis=1)\n",
    "dfl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl.groupby('l_class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = datalist.drop(['l_class', 'timestamp'], axis=1)\n",
    "dfs.groupby('s_class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.img_path.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_test_img_path =[\n",
    "    \"../data/insta_frames/4gokan/4gokan_inside/4gokan_inside_0_img_000240.png\",\n",
    "    \"../data/insta_frames/4gokan/4gokan_outside/4gokan_outside_0_img_000180.png\",\n",
    "    \"../data/insta_frames/5gokan-denkisogokan/5gokan-denkisogokan_1_img_000010.png\",\n",
    "    \"../data/insta_frames/5gokan-mediacenter/5gokan-mediacenter_0_img_000030.png\",\n",
    "    \"../data/insta_frames/5gokan/5gokan_1F/5gokan_1F_0_img_000070.png\",\n",
    "    \"../data/insta_frames/5gokan/5gokan_2F/5gokan_2F_2_img_000030.png\",\n",
    "    \"../data/insta_frames/5gokan/5gokan_3F/5gokan_3F_0_img_000040.png\",\n",
    "    \"../data/insta_frames/5gokan/5gokan_ent_east/5gokan_ent_east_2_img_000000.png\",\n",
    "    \"../data/insta_frames/5gokan/5gokan_lounge/5gokan_lounge_2_img_000060.png\",\n",
    "    \"../data/insta_frames/5gokan/5gokan_out_east/5gokan_out_east_0_img_000270.png\",\n",
    "    \"../data/insta_frames/5gokan/5gokan_parking/5gokan_parking_1_img_000170.png\",\n",
    "    \"../data/insta_frames/5gokan/5gokan_smoking/5gokan_smoking_0_img_000270.png\",\n",
    "    \"../data/insta_frames/5gokan/5gokan_stairs_cnt/5gokan_stairs_cnt_3_img_000010.png\",\n",
    "    \"../data/insta_frames/5gokan/5gokan_stairs_west/5gokan_stairs_west_0_img_000340.png\",\n",
    "    \"../data/insta_frames/8gokan/8gokan_1F/8gokan_1F_1_img_000000.png\",\n",
    "    \"../data/insta_frames/8gokan/8gokan_ent_north/8gokan_ent_north_0_img_000010.png\",\n",
    "    \"../data/insta_frames/8gokan/8gokan_ent_south/8gokan_ent_south_1_img_000070.png\",\n",
    "    \"../data/insta_frames/denkisogokan/denkisogokan_2F/denkisogokan_2F_2_img_000300.png\",\n",
    "    \"../data/insta_frames/denkisogokan/denkisogokan_3F/denkisogokan_3F_0_img_000010.png\",\n",
    "    \"../data/insta_frames/denkisogokan/denkisogokan_4F/denkisogokan_4F_0_img_000170.png\",\n",
    "    \"../data/insta_frames/denkisogokan/denkisogokan_elevator/denkisogokan_elevator_0_img_000220.png\",\n",
    "    \"../data/insta_frames/denkisogokan/denkisogokan_lounge/denkisogokan_lounge_1_img_000060.png\",\n",
    "    \"../data/insta_frames/denkisogokan/denkisogokan_stairs/denkisogokan_stairs_0_img_000120.png\",\n",
    "    \"../data/insta_frames/lab-lounge/lab-lounge_0_img_000170.png\",\n",
    "    \"../data/insta_frames/lab/lab_bs_cnt/lab_bs_cnt_0_img_000270.png\",\n",
    "    \"../data/insta_frames/lab/lab_corner/lab_corner_0_img_000270.png\",\n",
    "    \"../data/insta_frames/lab/lab_desk/lab_desk_8_img_000210.png\",\n",
    "    \"../data/insta_frames/lab/lab_desk_table/lab_desk_table_3_img_000150.png\",\n",
    "    \"../data/insta_frames/lab/lab_ent/lab_ent_0_img_000020.png\",\n",
    "    \"../data/insta_frames/lab/lab_printer/lab_printer_0_img_000030.png\",\n",
    "    \"../data/insta_frames/lab/lab_table/lab_table_0_img_000170.png\",\n",
    "    \"../data/insta_frames/lab/lab_wb_cnt/lab_wb_cnt_0_img_000120.png\",\n",
    "    \"../data/insta_frames/lab/lab_wb_ent/lab_wb_ent_1_img_000160.png\",\n",
    "    \"../data/insta_frames/lounge/lounge_1_img_000060.png\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_lab_img = [\n",
    "    \"../data/insta_frames/lab-lounge/lab-lounge_0_img_000170.png\",\n",
    "    \"../data/insta_frames/lab-lounge/lab-lounge_0_img_000220.png\",\n",
    "    \"../data/insta_frames/lab-lounge/lab-lounge_1_img_000230.png\",\n",
    "    \"../data/insta_frames/lab/lab_bs_cnt/lab_bs_cnt_0_img_000020.png\",\n",
    "    \"../data/insta_frames/lab/lab_bs_cnt/lab_bs_cnt_0_img_000270.png\",\n",
    "    \"../data/insta_frames/lab/lab_bs_cnt/lab_bs_cnt_0_img_000140.png\",\n",
    "    \"../data/insta_frames/lab/lab_corner/lab_corner_0_img_000270.png\",\n",
    "    \"../data/insta_frames/lab/lab_corner/lab_corner_1_img_000200.png\",\n",
    "    \"../data/insta_frames/lab/lab_corner/lab_corner_1_img_000280.png\",\n",
    "    \"../data/insta_frames/lab/lab_desk/lab_desk_0_img_000070.png\",\n",
    "    \"../data/insta_frames/lab/lab_desk/lab_desk_1_img_000240.png\",\n",
    "    \"../data/insta_frames/lab/lab_desk/lab_desk_8_img_000210.png\",\n",
    "    \"../data/insta_frames/lab/lab_desk_table/lab_desk_table_0_img_000170.png\",\n",
    "    \"../data/insta_frames/lab/lab_desk_table/lab_desk_table_0_img_000220.png\",\n",
    "    \"../data/insta_frames/lab/lab_desk_table/lab_desk_table_3_img_000150.png\",\n",
    "    \"../data/insta_frames/lab/lab_ent/lab_ent_0_img_000020.png\",\n",
    "    \"../data/insta_frames/lab/lab_printer/lab_printer_0_img_000030.png\",\n",
    "    \"../data/insta_frames/lab/lab_printer/lab_printer_0_img_000220.png\",\n",
    "    \"../data/insta_frames/lab/lab_printer/lab_printer_0_img_000170.png\",\n",
    "    \"../data/insta_frames/lab/lab_table/lab_table_0_img_000170.png\",\n",
    "    \"../data/insta_frames/lab/lab_table/lab_table_1_img_000290.png\",\n",
    "    \"../data/insta_frames/lab/lab_table/lab_table_4_img_000100.png\",\n",
    "    \"../data/insta_frames/lab/lab_wb_cnt/lab_wb_cnt_0_img_000120.png\",\n",
    "    \"../data/insta_frames/lab/lab_wb_cnt/lab_wb_cnt_0_img_000120.png\",\n",
    "    \"../data/insta_frames/lab/lab_wb_cnt/lab_wb_cnt_0_img_000120.png\",\n",
    "    \"../data/insta_frames/lab/lab_wb_ent/lab_wb_ent_1_img_000160.png\",\n",
    "    \"../data/insta_frames/lab/lab_wb_ent/lab_wb_ent_1_img_000160.png\",\n",
    "    \"../data/insta_frames/lab/lab_wb_ent/lab_wb_ent_1_img_000160.png\",\n",
    "    \"../data/insta_frames/lounge/lounge_0_img_000020.png\",\n",
    "    \"../data/insta_frames/lounge/lounge_1_img_000060.png\",\n",
    "    \"../data/insta_frames/lounge/lounge_1_img_000210.png\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "le = LabelEncoder()\n",
    "le.fit(dfs.s_class)\n",
    "dfs[\"labels\"] = le.transform(dfs.s_class)\n",
    "dfs.groupby('labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "cor_table = dfs.groupby('labels').s_class.unique()\n",
    "cor_table = pd.DataFrame(cor_table)\n",
    "cor_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "cor_table.to_csv('cor_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "dfs = dfs.drop(['s_class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "x = []\n",
    "for i in range(len(dfs.img_path)):\n",
    "    image = img_to_array(load_img(dfs.img_path[i], target_size=(224,224)))\n",
    "    x.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "y = dfs.labels\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "#正規化\n",
    "x = np.array(x, dtype='float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "#np.array形式のデータを保存　x, y\n",
    "np.save(file='x.npy', arr=x)\n",
    "np.save(file='y.npy', arr=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, yをload\n",
    "x = np.load(file='x.npy')\n",
    "y = np.load(file='y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像データを入力の形で保存しておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test & validation set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_valid, y, y_valid = train_test_split(x,y, random_state=42, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA(探索的データ解析)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,18))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05, wspace=0.05)\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(x[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BagNets17　Using VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Activation, add, Add, Dropout, BatchNormalization, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bagnets.kerasnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = bagnets.kerasnet.bagnet17()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top(全結合層など)はデフォルトだとImageNetの全クラス数1000での出力になるので，\n",
    "自作のアーキテクチャを使用する\n",
    "top以外のモデルの重みは(ImageNetで)固定しない→学習をする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning(Flozen(Not training vgg layers))\n",
    "training all layers -> acc: 0.1..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs = Input(shape=(224,224,3))\n",
    "x1 = vgg_model(inputs)\n",
    "x2 = Flatten()(x1)\n",
    "x3 = Dense(256, activation='relu')(x2)\n",
    "prediction = Dense(num_s_class, activation='softmax')(x3)\n",
    "full_model = Model(inputs=inputs, outputs=prediction)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto')\n",
    "for layer in vgg_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "full_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [l for l in vgg_model.layers]\n",
    "inputs = Input(shape=(3,224,224))\n",
    "x = layers[1](inputs)\n",
    "for i in range(2,len(layers)-1):\n",
    "    layers[i].trainable = False\n",
    "    x = layers[i](x)\n",
    "x = Dense(num_s_class, activation='softmax')(x)\n",
    "\n",
    "full_model = Model(input=layers[0].input, output=x)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto')\n",
    "full_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # 層化抽出法(Stratified sampling)&KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "cvscores = []\n",
    "#Stratified KFoldはlabel encoding化した整数ベクトルでないともちいることができない\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #One-hot化　CNNに入出力できるように整形\n",
    "    y_train = np_utils.to_categorical(y_train, num_s_class)\n",
    "    y_test = np_utils.to_categorical(y_test, num_s_class)\n",
    "    full_model.fit(x_train, y_train, verbose=1, batch_size=batch_size, epochs=n_epochs,\n",
    "              callbacks=[early_stopping], validation_split=0.2)\n",
    "    scores = full_model.evaluate(x_test, y_test)\n",
    "    print(\"%s: %.2f%%\" % (full_model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = full_model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = np_utils.to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_valid)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.sparse.csgraph import connected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmx = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(cmx, annot=True)\n",
    "plt.show()\n",
    "print('accuracy: {}'.format(accuracy_score\n",
    "(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_table = pd.read_csv('cor_table.csv')\n",
    "print(cor_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中間層特徴量の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = vgg_model.get_layer('block1_pool').output\n",
    "output1 = GlobalMaxPooling2D()(x1)\n",
    "block_model1 = Model(inputs=vgg_model.input, outputs=output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = vgg_model.get_layer('block2_pool').output\n",
    "output2 = GlobalMaxPooling2D()(x2)\n",
    "block_model2 = Model(inputs=vgg_model.input, outputs=output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = vgg_model.get_layer('block3_pool').output\n",
    "output3 = GlobalMaxPooling2D()(x3)\n",
    "block_model3 = Model(inputs=vgg_model.input, outputs=output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4 = vgg_model.get_layer('block4_pool').output\n",
    "output4 = GlobalMaxPooling2D()(x4)\n",
    "block_model4 = Model(inputs=vgg_model.input, outputs=output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5 = vgg_model.get_layer('block5_pool').output\n",
    "output5 = GlobalMaxPooling2D()(x5)\n",
    "block_model5 = Model(inputs=vgg_model.input, outputs=output5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = block_model1.predict(x_train)\n",
    "block2 = block_model2.predict(x_train)\n",
    "block3 = block_model3.predict(x_train)\n",
    "block4 = block_model4.predict(x_train)\n",
    "block5 = block_model5.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(block1.shape)\n",
    "print(block2.shape)\n",
    "print(block3.shape)\n",
    "print(block4.shape)\n",
    "print(block5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# block1の特徴ベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_name = 'jet'\n",
    "cmap = plt.get_cmap(cm_name, num_s_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hotから整数値ベクトルに変換\n",
    "y_train_vec = []\n",
    "for i in range(len(y_train)):\n",
    "    y_train_vec.append(np.argmax(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = pca.fit_transform(block1)\n",
    "#　主成分分析の例(1層目)\n",
    "df_feature1 = pd.DataFrame(feature1)\n",
    "print(df_feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature1[:,0],feature1[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(block1)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# block2の特徴ベクトル "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2 = pca.fit_transform(block2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature2[:,0],feature2[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(block2)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# block3の特徴ベクトル "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature3 = pca.fit_transform(block3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature3[:,0],feature3[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(block3)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# block4の特徴ベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature4 = pca.fit_transform(block4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature4[:,0],feature4[:,1], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(block4)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# block5の特徴ベクトル "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature5 = pca.fit_transform(block5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(feature5[:,0],feature5[:,1],marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(block5)\n",
    "ev_ratio = pca.explained_variance_ratio_\n",
    "ev_ratio = np.hstack([0, ev_ratio.cumsum()])\n",
    "plt.xlabel(\"num of components\")\n",
    "plt.ylabel(\"explained variance ratio\")\n",
    "plt.plot(ev_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure().add_subplot(111, projection='3d')\n",
    "ax.scatter(feature5[:,0],feature5[:,1], feature5[:,3], marker=\".\", c=y_train_vec, cmap=cmap)\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_zlabel(\"PC3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "for i in range(num_s_class):\n",
    "    true.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "grad_last_conv = full_model.get_layer(\"block5_conv3\")\n",
    "model_output = full_model.output[:,0]\n",
    "grads = K.gradients(model_output, grad_last_conv.output)[0]\n",
    "pooled_grads = K.mean(grads, axis=(0,1,2))\n",
    "iterate = K.function([full_model.input], [pooled_grads, grad_last_conv.output[0]])\n",
    "\n",
    "for n in range(len(grad_lab_img)):\n",
    "    img_keras = image.load_img(grad_lab_img[n], target_size=(224, 224))\n",
    "    img_tensor = image.img_to_array(img_keras)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "    predicts = full_model.predict(img_tensor)\n",
    "    s_class_num = np.argmax(predicts)\n",
    "    pred.append(s_class_num)\n",
    "    img_tensor /= 255.\n",
    "    pooled_grads_val, conv_output_val = iterate([img_tensor])\n",
    "    for i in range(pooled_grads_val.shape[0]):\n",
    "        conv_output_val[:, :, i] *= pooled_grads_val[i]\n",
    "    heatmap = np.mean(conv_output_val, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    img = cv2.imread(grad_lab_img[n])\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = heatmap * 0.4 + img\n",
    "    save_dir = '../data/gradcam_img/VGG16'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\t# Make a directory\n",
    "    #保存先ディレクトリ名はその画像のクラス，画像の予測値を画像の名前に書き込む\n",
    "    cv2.imwrite(save_dir+'/heatmap_wrong_pred_'+s_classlist[s_class_num]+'_'+str(n)+'_'+'.jpg', superimposed_img)\n",
    "    print('Saved: ', save_dir+'/heatmap_wrong_pred_'+s_classlist[s_class_num]+'.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def grad_cam(input_model, image, cls, layer_name):\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    y_c = input_model.output[0, cls]\n",
    "    conv_output = input_model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "    # Normalize if necessary\n",
    "    # grads = normalize(grads)\n",
    "    gradient_function = K.function([input_model.input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "\n",
    "    # Process CAM\n",
    "    cam = cv2.resize(cam, (W, H), cv2.INTER_LINEAR)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam_max = cam.max() \n",
    "    if cam_max != 0: \n",
    "        cam = cam / cam_max\n",
    "    return cam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for n in range(len(grad_lab_img)):\n",
    "    cam = grad_cam(input_model=full_model, image=grad_lab_img[n], cls=-1, layer_name=\"block5_conv3\")\n",
    "    save_dir = '../data/gradcam_test/VGG16'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\t# Make a directory\n",
    "    #保存先ディレクトリ名はその画像のクラス，画像の予測値を画像の名前に書き込む\n",
    "    cv2.imwrite(save_dir+'/heatmap_wrong_pred_'+s_classlist[s_class_num]+'_'+str(n)+'_'+'.jpg', cam)\n",
    "    print('Saved: ', save_dir+'/heatmap_wrong_pred_'+s_classlist[s_class_num]+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grad = pd.DataFrame(grad_lab_img)\n",
    "df_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmx = confusion_matrix(true, pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(cmx, annot=True)\n",
    "plt.ylabel(\"truth\")\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_table = pd.read_csv('cor_table.csv')\n",
    "print(cor_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction->edge ==> padding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
